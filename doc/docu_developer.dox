/**
@page developer Developer information


@section general General program layout Information
CASS has two basic parts the input and analyze. Where the input part gets the data
from either file or shared memory and the analyze part will analyze the data.
Both of them are threaded, where the input is always just one thread and the
analyze part consists of more threads. The linkage between the input threads
and the analysis thread is done by cass::RingBuffer. This is a buffer that
contains the amount of cass::CASSEvent elements that can be chosen by setting
cass::RingBufferSize. It allows to retrieve elements that should be filled with
new data and elements whose contents should be analyzed.


@section input Input part of CASS
Both inputs will do the following tasks after they retrieved the data from LCLS:
- get fillable (empty) cass::CASSEvent element from cass::RingBuffer
- convert LCLS data to cass::CASSEvent data and fill the later with the data
- put cass::CASSEvent back into cass::RingBuffer

To convert the data the cass::FormatConverter singleton is used. This will
iterate through the LCLS datagram and call the right cass::ConversionBackend
object that will convert the xtc data to cass::CASSEvent data. The user can
select what part of the data he wants to have converted by setting up which
converters he wants to use. Please refer to the documentation of
cass::FormatConverter and the converters for details.

@section offline_input Offline input of CASS
The input part that will read the data from file in offline mode is handled by
the class cass::FileInput. This just parses the input file containing the file
names to analyze, put them into string list and then goes through that list.
For each file it will retrieve an event and convert the data to cass::CASSEvent
object. The later was retrieved from the cass::RingBuffer and then later put back
into it.


@section online_input Online input of CASS
In the online mode the input part will read the data from the LCLS shared memory.
The corrosponding class is cass::SharedMemoryInput. It derives from the
Pds::XtcMonitorClient class provided by LCLS. This class will do all the
communication between the shared memory and CASS. Once it retrieved new data
(in LCLS terms this is called datagram) it will call the overwritten
cass::SharedMemoryInput::processDgram() member. Here the datagram will be
converted to a cass::CASSEvent which is retrieved from the cass::RingBuffer
before. After that it is put back into the cass::RingBuffer.



@section analysis Analysis part of CASS
The analysis part is done by multiple threads. One can set the number of analysis
threads by modifying the cass::NbrOfWorkers variable. Each
analysis thread is a cass::Worker object, which are handled by the cass::Workers
object. Each one of the cass::Worker objects will do the following until it is
told to quit:
- retrieve an analyzable (non empty) cass::CASSEvent element from cass::RingBuffer
- pre analyze the cass::CASSEvent element using the cass::Analyzer singleton
- post analyze the cass::CASSEvent element using the cass::PostProcessors
  singleton.
- put the event back to the ringbuffer to be refilled again.

The cass::Analyzer singleton will pass the cass event to all user selected pre
analyzers to pre process the data. The cass::PostProcessor will pass the event
to all user defined postprocessors to be postprocessed. For further details on
how to select what postprocessors should run please see section @ref inifilesetup.
A list of analyzers can be found in cass::Analyzer in which you can also find
links to specific documentation of each analyzer.

@section communication Communicating with CASS
CASS is using SOAP to communicate with the viewers. The class that handles these
communication is cass::SoapServer. It uses a cass::HistogramGetter object to
retrieve a requested histogram from the available postprocessors.



@section pplayout The post processors
Each post post processor has a list of pointers to histograms that it has
processed yet. This is to ensure that it will not evaluate the same event
over and over again. When it has already processed one event it will return the
resulting histogram associated with this event.\n
Some of the post processors do not have a separate result for each event,
i.e. the summing up and averaging post processors. They are based upon the
accumulating postprocessor base class.\n
To make sure that in the cass::PostProcessor::process() function one will
always use the right histograms a reference to it will be passed to this function.
The following happens in each post processor when cass::PostProcessors::process()
will call the cass::PostProcessor::processEvent() member of each normal
post processor:
- search in the histogram list whether there is a an entry that has the
  cass::CASSEvent::_id as first part of the pair.
- if so then just return the second part of the pair.
- if not, check if the condition is true and in this case evaluate it.

@section addnew Adding new functionality to CASS

Please refer to @ref develnotes for the rules when developing code

@section newpp How to add a new PostProcessor
A new "normal" PostProcessor needs to inherit from cass::PostProcessor. The most
important function that need to be overwritten are
cass::PostProcessor::loadSettings() and
cass::PostProcessor::process().
In cass::PostProcessor::loadSettings() you need to setup the
dependencies you are relying on, the general available parameters
and most importantly the resulting histogram. With
cass::PostProcessor::setupCondition() you set up that your PostProcessor has a
condition.

cass::PostProcessor::setupGeneral() will setup all the default parameters that
are available for post processors. Optionally you can use the function member
cass::PostProcessor::setupDependency() to set up the dependencies you
rely on.

To initialize the list of cached resulting histograms you need to call the
cass::PostProcessor::createHistList() member. This member needs to have a
shared pointer to the histogram that will work as a result of the PostProcessor
passed.

Most PostProcessors rely on the fact that a histograms shape or size will not be
changed during the processing step. (An exception to this rule are the table like
PostProcessors.) Therefore one needs to ensure that the result Histogram will
have the right size or shape during the load settings step.

The resulting histogram is write locked before calling the cass::PostProcessor::process()
function. There is no need to lock it again in definition of you PostProcessor.
However the Histogram of the PostProcessor you depend on is not locked. Therefore
one needs to readlock it before trying to read contents from it to ensure its
contents are not changed during the time one reads them. It is recommended to
use the locker facility that Qt provides. Eg:
@verbatim
// retrieve the histogram for this event from the dependency (_pHist) and cast it to an 1d histogram
const Histogram1DFloat& one
    (dynamic_cast<const Histogram1DFloat&>(_pHist->result(evt.id())));

// lock the histogram for read access
QReadLocker lock(&one.lock);
@endverbatim


When you are done coding your postprocessor you need to make it available to
the user. To do this you need to complete the following steps:
- in cass/postprocessing/postprocessor.h add the number and a short description
  in the description part.
- in cass/postprocessing/postprocessor.h add an entry with your id in the
  cass::PostProcessors::id_t enum.
- in cass/postprocessing/postprocessor.cpp add your id in the
  cass::PostProcessors::create() member to the switch statement. Just use the
  other entries as example.



@section newcon How to add a new Converter
Your converter has to inherit from cass::ConversionBackend and it should be a
singleton. This means that it should have a static member function called
instance that will return a cass::ConversionBackend::converterPtr_t object that
contains the singleton pointer.\n
In the constructor of the class you need to fill the
cass::ConversionBackend::_pdsTypeList with the type id's from the LCLS that you
want the converter to react on.\n
You need to overwrite cass::ConversionBackend::operator()() with the code that
extracts the desired data from the datagram and put it into the cass::CASSEvent.\n
Once you have set up your converter, you need to modify
cass::ConversionBackend::instance() and add an @c else-if-statment that returns
converter. Please document in cass/format_converter.h which string will return
your the singleton of your converter.

@section feature How to add a feature to cass using git
The master branch should be linear, to be able to create a changelog from the
commit history at some point. Optimally all feature branches should be rebased
to a few single commits that would explain in the changelog what was done. For
now we just keep merging every commit to the master branch.

On your local repository ensure that everything is up to date:
@verbatim
git pull origin
@endverbatim
Make sure that the feature branch and the master branch are up to date. One
might have to checkout both branches and then redo the pull command.
Make sure that branch can be fast forward merged into master by rebasing it to
master.
@verbatim
git checkout %feature branch name%
git rebase master (only if cannot be fast forwarded)
@endverbatim
Now merge the feature branch into master
@verbatim
git checkout master
git merge %feature branch name%
@endverbatim
Give the new master branch head a new annotated tag following the Tagging rules
@verbatim
git tag -a major.minor.bugfix -m”version major.minor.bugfix”
@endverbatim
Push the tags to the repo server before pushing the changes in master. Otherwise
the tag number will not appear in the automatically generated documentation.
@verbatim
git push origin --tags
git push origin
@endverbatim
The last command might take a while, because when the master branch has changed
a hook script will automatically create the new documentation and the new
binaries.
Then remove the feature branch from all the repositories (locals and remote)
@verbatim
git push origin --delete %feature branch name%
git branch -D %feature branch name%
@endverbatim
Make sure that you update the other repositories that you might work on in
different places by doing a
@verbatim
git pull (--rebase)
git remote prune origin
@endverbatim

@subsection tagging Tagging
The tags should follow the versioning scheme:
@verbatim
major.minor.bugfix
@endverbatim
Where major should only be changed when a complete new revision that is not
backward compatible and where the whole underlying concept changed was touched.
A increase of minor indicates a new feature or new functionality that was added
to the program.

Increase the bugfix if just a fix for a problem was added.

Further details can be found in the @ref taginfo file
*/

/**
\page develnotes Developer Notes
@include "README.devel"
*/

/**
\page taginfo VERSIONING
@include "VERSION"
*/
